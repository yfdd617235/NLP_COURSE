{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bd41f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hola,', '¿cómo', 'estás?']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hola, ¿Cómo estás?\"\n",
    "text = text.lower()\n",
    "tokens = text.split()\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4ccb7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto = \"El gato es negro y el perro es blanco\"\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1206a428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tenidos', 'mi', 'habremos', 'fuiste', 'les', 'estoy', 'tuvieseis', 'fueran', 'sentido', 'vosotros', 'hubiera', 'teníais', 'tanto', 'habríais', 'habida', 'antes', 'hubo', 'habéis', 'nada', 'habrían', 'sentidos', 'ante', 'muchos', 'estarás', 'estaremos', 'habrías', 'ellas', 'se', 'uno', 'estaría', 'tendría', 'tuvieron', 'estaríais', 'está', 'estén', 'estuviera', 'cuando', 'para', 'mío', 'me', 'estuviese', 'los', 'eso', 'al', 'fui', 'él', 'sintiendo', 'nosotras', 'la', 'tendrá', 'de', 'haya', 'tened', 'tendremos', 'hubiésemos', 'serían', 'tuyas', 'estuvimos', 'suyo', 'ya', 'hubieras', 'fueses', 'fue', 'sentida', 'estuvo', 'desde', 'suyas', 'ni', 'estarías', 'un', 'estabais', 'sea', 'habríamos', 'todo', 'estos', 'esa', 'estando', 'seré', 'seas', 'fuese', 'tengáis', 'durante', 'tenéis', 'quien', 'fueras', 'tuyo', 'tengan', 'estuvieseis', 'esas', 'mí', 'habría', 'habíamos', 'tendrías', 'esté', 'estas', 'os', 'suya', 'mis', 'tenemos', 'tuyos', 'estados', 'ellos', 'hubieses', 'seamos', 'seríais', 'hubimos', 'éramos', 'estuvieran', 'ha', 'estuve', 'tuvimos', 'hubiéramos', 'algunas', 'otros', 'vuestro', 'tiene', 'estemos', 'ella', 'mía', 'serán', 'tuviese', 'hubiesen', 'contra', 'sois', 'hubiese', 'fuimos', 'a', 'estábamos', 'tuya', 'somos', 'estuviste', 'porque', 'otra', 'tendrían', 'estará', 'fuisteis', 'donde', 'soy', 'estuvierais', 'nuestros', 'te', 'sobre', 'todos', 'con', 'sin', 'fuerais', 'siente', 'tuvo', 'tengo', 'el', 'e', 'seréis', 'tenían', 'tengas', 'hubieron', 'estaríamos', 'estuvieron', 'también', 'tienes', 'pero', 'estabas', 'estuvisteis', 'estarán', 'su', 'esto', 'sería', 'he', 'estés', 'eres', 'seríamos', 'lo', 'habías', 'esta', 'habrás', 'del', 'como', 'estaba', 'sí', 'unos', 'son', 'tenido', 'estáis', 'erais', 'tendrás', 'poco', 'eran', 'tuviesen', 'hayamos', 'suyos', 'cual', 'estad', 'tuviera', 'has', 'hayan', 'hubisteis', 'estar', 'teníamos', 'nuestras', 'estuvieses', 'nos', 'muy', 'tienen', 'nuestro', 'tuvieran', 'habiendo', 'ese', 'había', 'estás', 'serás', 'será', 'fueron', 'vuestra', 'tuviste', 'serías', 'seremos', 'las', 'están', 'habían', 'yo', 'hube', 'habido', 'una', 'no', 'estaréis', 'habíais', 'eras', 'tu', 'fuéramos', 'esos', 'hasta', 'fuesen', 'tuviésemos', 'tú', 'tendrán', 'estaré', 'han', 'teniendo', 'hubieseis', 'vosotras', 'tuve', 'tuvieses', 'vuestras', 'sus', 'estuvieras', 'tenías', 'estuviéramos', 'sentid', 'estarían', 'tendréis', 'y', 'tendríamos', 'algo', 'sean', 'habrá', 'era', 'estuviesen', 'tus', 'nosotros', 'hayáis', 'tuvisteis', 'tenga', 'tuviéramos', 'fuera', 'nuestra', 'algunos', 'habidas', 'habidos', 'míos', 'hemos', 'sentidas', 'estaban', 'hayas', 'ti', 'tuvierais', 'qué', 'entre', 'que', 'tenía', 'hubieran', 'otro', 'mías', 'habré', 'le', 'seáis', 'hay', 'tendré', 'este', 'otras', 'es', 'tuvieras', 'hubierais', 'estado', 'estada', 'o', 'tenida', 'estadas', 'fueseis', 'vuestros', 'tenidas', 'estuviésemos', 'por', 'en', 'más', 'estéis', 'tengamos', 'hubiste', 'tendríais', 'habréis', 'estamos', 'habrán', 'quienes', 'fuésemos', 'mucho'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# stopwords: Words very common than does not give much meaning\n",
    "from nltk.corpus import stopwords\n",
    "#from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae60aa0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to C:\\Users\\JEFE\n",
      "[nltk_data]    |     DE ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to C:\\Users\\JEFE\n",
      "[nltk_data]    |     DE ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to C:\\Users\\JEFE\n",
      "[nltk_data]    |     DE ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package english_wordnet to C:\\Users\\JEFE\n",
      "[nltk_data]    |     DE ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package english_wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to C:\\Users\\JEFE\n",
      "[nltk_data]    |     DE ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package mock_corpus to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mock_corpus is already up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to C:\\Users\\JEFE\n",
      "[nltk_data]    |     DE ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to C:\\Users\\JEFE\n",
      "[nltk_data]    |     DE ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to C:\\Users\\JEFE\n",
      "[nltk_data]    |     DE ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt_tab to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt_tab is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to C:\\Users\\JEFE\n",
      "[nltk_data]    |     DE ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to C:\\Users\\JEFE\n",
      "[nltk_data]    |     DE ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to C:\\Users\\JEFE\n",
      "[nltk_data]    |     DE ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets_json to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets_json is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to C:\\Users\\JEFE\n",
      "[nltk_data]    |     DE ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to C:\\Users\\JEFE\n",
      "[nltk_data]    |     DE ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to C:\\Users\\JEFE\n",
      "[nltk_data]    |     DE ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to C:\\Users\\JEFE\n",
      "[nltk_data]    |     DE ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['El', 'gato', 'es', 'negro', 'y', 'el', 'perro', 'es', 'blanco']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to C:\\Users\\JEFE DE\n",
      "[nltk_data]    |     ING. INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]    |     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('all')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "texto = \"El gato es negro y el perro es blanco\"\n",
    "tokens = word_tokenize(texto)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55c49060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['el', 'gato', 'es', 'negro', 'y', 'el', 'perro', 'es', 'blanco']\n"
     ]
    }
   ],
   "source": [
    "texto = \"El gato es negro y el perro es blanco\"\n",
    "texto = texto.lower()\n",
    "tokens = word_tokenize(texto)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54875847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gato', 'negro', 'perro', 'blanco']\n"
     ]
    }
   ],
   "source": [
    "texto_filtrado = [word for word in tokens if not word in stop_words]\n",
    "print(texto_filtrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a6974a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\JEFE DE ING.\n",
      "[nltk_data]     INDUSTR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fd4d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camin\n",
      "camin\n",
      "camin\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "#Crear el stemmer en español\n",
    "\n",
    "#Probarlo en la palabra \"caminar\"\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "print(stemmer.stem('caminando'))\n",
    "print(stemmer.stem('caminar'))\n",
    "print(stemmer.stem('camino'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd253499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy -q\n",
    "python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57ee4df8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConfigError",
     "evalue": "unable to infer type for attribute \"REGEX\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConfigError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspacy\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#Cargar el modelo en español\u001b[39;00m\n\u001b[32m      4\u001b[39m nlp = spacy.load(\u001b[33m'\u001b[39m\u001b[33mes_core_news_sm\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\spacy\\__init__.py:13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# These are imported as part of the API\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mthinc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Config, prefer_gpu, require_cpu, require_gpu  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m util\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mabout\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\spacy\\pipeline\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mattributeruler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AttributeRuler\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdep_parser\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DependencyParser\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01medit_tree_lemmatizer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EditTreeLemmatizer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\spacy\\pipeline\\attributeruler.py:10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m util\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Errors\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlanguage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Language\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmatcher\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Matcher\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mscorer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Scorer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\spacy\\language.py:46\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlang\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtokenizer_exceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BASE_EXCEPTIONS, URL_MATCH\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlookups\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_lookups\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipe_analysis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m analyze_pipes, print_pipe_analysis, validate_attrs\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mschemas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     48\u001b[39m     ConfigSchema,\n\u001b[32m     49\u001b[39m     ConfigSchemaInit,\n\u001b[32m   (...)\u001b[39m\u001b[32m     52\u001b[39m     validate_init_settings,\n\u001b[32m     53\u001b[39m )\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mscorer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Scorer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\spacy\\pipe_analysis.py:6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwasabi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m msg\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Errors\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtokens\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Doc, Span, Token\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dot_to_dict\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# This lets us add type hints for mypy etc. without causing circular imports\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\spacy\\tokens\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_serialize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DocBin\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdoc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Doc\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmorphanalysis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MorphAnalysis\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\spacy\\tokens\\_serialize.py:14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Errors\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SimpleFrozenList, ensure_path\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvocab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Vocab\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dict_proxies\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SpanGroups\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdoc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DOCBIN_ALL_ATTRS \u001b[38;5;28;01mas\u001b[39;00m ALL_ATTRS\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\spacy\\vocab.pyx:1\u001b[39m, in \u001b[36minit spacy.vocab\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\spacy\\tokens\\doc.pyx:49\u001b[39m, in \u001b[36minit spacy.tokens.doc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\spacy\\schemas.py:195\u001b[39m\n\u001b[32m    191\u001b[39m         obj = converted\n\u001b[32m    192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m validate(TokenPatternSchema, {\u001b[33m\"\u001b[39m\u001b[33mpattern\u001b[39m\u001b[33m\"\u001b[39m: obj})\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mTokenPatternString\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mBaseModel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[43mREGEX\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mOptional\u001b[49m\u001b[43m[\u001b[49m\u001b[43mUnion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mStrictStr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTokenPatternString\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mField\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malias\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mregex\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m    \u001b[49m\u001b[43mIN\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mOptional\u001b[49m\u001b[43m[\u001b[49m\u001b[43mList\u001b[49m\u001b[43m[\u001b[49m\u001b[43mStrictStr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mField\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malias\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43min\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\pydantic\\v1\\main.py:221\u001b[39m, in \u001b[36mModelMetaclass.__new__\u001b[39m\u001b[34m(mcs, name, bases, namespace, **kwargs)\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_valid_field(var_name) \u001b[38;5;129;01mand\u001b[39;00m var_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m annotations \u001b[38;5;129;01mand\u001b[39;00m can_be_changed:\n\u001b[32m    220\u001b[39m     validate_field_name(bases, var_name)\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     inferred = \u001b[43mModelField\u001b[49m\u001b[43m.\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvar_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m        \u001b[49m\u001b[43mannotation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mannotations\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mUndefined\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_validators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_validators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m var_name \u001b[38;5;129;01min\u001b[39;00m fields:\n\u001b[32m    229\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m lenient_issubclass(inferred.type_, fields[var_name].type_):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\pydantic\\v1\\fields.py:504\u001b[39m, in \u001b[36mModelField.infer\u001b[39m\u001b[34m(cls, name, value, annotation, class_validators, config)\u001b[39m\n\u001b[32m    501\u001b[39m     required = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    502\u001b[39m annotation = get_annotation_from_field_info(annotation, field_info, name, config.validate_assignment)\n\u001b[32m--> \u001b[39m\u001b[32m504\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtype_\u001b[49m\u001b[43m=\u001b[49m\u001b[43mannotation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m    \u001b[49m\u001b[43malias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfield_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43malias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_validators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_validators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdefault_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfield_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequired\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequired\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfield_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfield_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\pydantic\\v1\\fields.py:434\u001b[39m, in \u001b[36mModelField.__init__\u001b[39m\u001b[34m(self, name, type_, class_validators, model_config, default, default_factory, required, final, alias, field_info)\u001b[39m\n\u001b[32m    432\u001b[39m \u001b[38;5;28mself\u001b[39m.shape: \u001b[38;5;28mint\u001b[39m = SHAPE_SINGLETON\n\u001b[32m    433\u001b[39m \u001b[38;5;28mself\u001b[39m.model_config.prepare_field(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m434\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\pydantic\\v1\\fields.py:544\u001b[39m, in \u001b[36mModelField.prepare\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprepare\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    538\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    539\u001b[39m \u001b[33;03m    Prepare the field but inspecting self.default, self.type_ etc.\u001b[39;00m\n\u001b[32m    540\u001b[39m \n\u001b[32m    541\u001b[39m \u001b[33;03m    Note: this method is **not** idempotent (because _type_analysis is not idempotent),\u001b[39;00m\n\u001b[32m    542\u001b[39m \u001b[33;03m    e.g. calling it it multiple times may modify the field and configure it incorrectly.\u001b[39;00m\n\u001b[32m    543\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m544\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_default_and_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    545\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.type_.\u001b[34m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m ForwardRef \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.type_.\u001b[34m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m DeferredType:\n\u001b[32m    546\u001b[39m         \u001b[38;5;66;03m# self.type_ is currently a ForwardRef and there's nothing we can do now,\u001b[39;00m\n\u001b[32m    547\u001b[39m         \u001b[38;5;66;03m# user will need to call model.update_forward_refs()\u001b[39;00m\n\u001b[32m    548\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\pydantic\\v1\\fields.py:576\u001b[39m, in \u001b[36mModelField._set_default_and_type\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    573\u001b[39m     \u001b[38;5;28mself\u001b[39m.annotation = \u001b[38;5;28mself\u001b[39m.type_\n\u001b[32m    575\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.type_ \u001b[38;5;129;01mis\u001b[39;00m Undefined:\n\u001b[32m--> \u001b[39m\u001b[32m576\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m errors_.ConfigError(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33munable to infer type for attribute \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.required \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m default_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    579\u001b[39m     \u001b[38;5;28mself\u001b[39m.allow_none = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mConfigError\u001b[39m: unable to infer type for attribute \"REGEX\""
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "#Cargar el modelo en español\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "#Crear un documento\n",
    "doc = nlp('caminar caminando caminó')\n",
    "\n",
    "#Imprimir el texto y el lema de cada token\n",
    "for token in doc:\n",
    "    print(token.text, \"->\", token.lemma)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
